# An√°lise Completa das Bases de Dados do Replit

## üìä Vis√£o Geral

An√°lise detalhada das 10 tabelas exportadas do PostgreSQL do Replit, com foco especial em **knowledge_base** e **indicator_metadata**.

---

## üìã Invent√°rio das Tabelas

| Tabela | Tamanho | Registros | Status | Observa√ß√µes |
|--------|---------|-----------|--------|-------------|
| `territories` | 38 KB | **140** | ‚úÖ Completa | Todos os territ√≥rios com coordenadas |
| `economic_indicators` | 164 KB | **700** | ‚úÖ Completa | 4 dimens√µes √ó 140 √ó 5 anos |
| `social_indicators` | 458 KB | **1.114** | ‚ö†Ô∏è Extra | +414 registros (59% a mais) |
| `territorial_indicators` | 163 KB | **700** | ‚úÖ Completa | Dados territoriais OK |
| `environmental_indicators` | 244 KB | **1.400** | ‚ö†Ô∏è Extra | +700 registros (100% a mais) |
| **`knowledge_base`** | **2 bytes** | **0** | ‚ùå **VAZIA** | **Cr√≠tico para IA** |
| **`indicator_metadata`** | **2 bytes** | **0** | ‚ùå **VAZIA** | **Cr√≠tico para UX** |
| `geometry_columns` | 2 bytes | 0 | ‚úÖ OK | Sistema PostGIS |
| `geography_columns` | 167 bytes | 1 | ‚úÖ OK | Sistema PostGIS |
| `spatial_ref_sys` | 7.3 MB | ~5.000 | ‚úÖ OK | Sistema PostGIS |

---

## üîç An√°lise Detalhada

### **1. Tabelas de Dados (‚úÖ Funcionando)**

#### **territories (140 registros)**

**Estrutura:**
```json
{
  "id": "17",
  "name": "Tocantins",
  "type": "Estado",
  "parent_id": null,
  "area": null,
  "metadata": {
    "regiao": "Norte",
    "codigo_ibge": "17"
  },
  "coordinates": "0101000020E6100000..." // PostGIS POINT
}
```

**Status:** ‚úÖ **Completa e funcional**
- 139 munic√≠pios + 1 estado
- Coordenadas geogr√°ficas presentes
- Metadados b√°sicos OK

---

#### **economic_indicators (700 registros)**

**Estrutura:**
```json
{
  "id": "uuid",
  "territory_id": "1720309",
  "year": 2021,
  "gdp": 606.98,
  "gdp_per_capita": 20390.45,
  "employment_rate": 59.9,
  "revenue": 80931064,
  "sector_distribution": {
    "servicos": 51.5,
    "industria": 27.8,
    "agricultura": 20.7
  }
}
```

**Status:** ‚úÖ **Completa**
- 140 territ√≥rios √ó 5 anos = 700 registros
- Dados econ√¥micos presentes
- Schema diferente do GitHub (mas funcional)

**Diferen√ßas do Schema GitHub:**
| GitHub | Replit | Status |
|--------|--------|--------|
| `total_revenue` | `revenue` | ‚ö†Ô∏è Nome diferente |
| `total_expenditure` | (ausente) | ‚ùå Faltando |
| `fiscal_balance` | (ausente) | ‚ùå Faltando |

---

#### **social_indicators (1.114 registros)**

**Estrutura:**
```json
{
  "id": "uuid",
  "territory_id": "1700251",
  "year": 2019,
  "idhm": 0.614,
  "population": 32277,
  "literacy_rate": 75.1,
  "income_per_capita": 694.92,
  "education_metrics": {
    "ideb_anos_finais": 4.1,
    "ideb_anos_iniciais": 5.2,
    "taxa_conclusao_medio": 66.8,
    "taxa_conclusao_fundamental": 80.3
  },
  "health_metrics": {
    "expectativa_vida": 75.8,
    "cobertura_vacinal": 92.7,
    "mortalidade_infantil": 16.5,
    "leitos_por_mil_habitantes": 3.44
  }
}
```

**Status:** ‚ö†Ô∏è **Funcional mas com dados extras**
- Esperado: 700 registros
- Obtido: 1.114 registros (+414, +59%)
- Poss√≠vel duplica√ß√£o ou dados sint√©ticos misturados

**Diferen√ßas do Schema GitHub:**
| GitHub | Replit | Status |
|--------|--------|--------|
| `hdi_m` | `idhm` | ‚ö†Ô∏è Nome diferente |
| Colunas separadas | `education_metrics` (JSON) | ‚ö†Ô∏è Estrutura diferente |
| Colunas separadas | `health_metrics` (JSON) | ‚ö†Ô∏è Estrutura diferente |

---

#### **territorial_indicators (700 registros)**

**Status:** ‚úÖ **Completa**
- 140 territ√≥rios √ó 5 anos = 700 registros
- Dados territoriais presentes

---

#### **environmental_indicators (1.400 registros)**

**Status:** ‚ö†Ô∏è **Funcional mas com dados extras**
- Esperado: 700 registros
- Obtido: 1.400 registros (+700, +100%)
- Poss√≠vel duplica√ß√£o ou m√∫ltiplas vers√µes

---

### **2. Tabelas Cr√≠ticas Vazias (‚ùå PROBLEMA)**

#### **knowledge_base (0 registros) ‚ùå CR√çTICO**

**Prop√≥sito:**
- Armazenar **an√°lises de IA** para cada territ√≥rio e dimens√£o
- Permitir **RAG** (Retrieval-Augmented Generation)
- Criar **mem√≥ria do sistema** para aprendizado cont√≠nuo
- Alimentar **dashboard** com insights prontos

**Schema Esperado (do GitHub):**
```sql
CREATE TABLE knowledge_base (
    id SERIAL PRIMARY KEY,
    territory_id VARCHAR(10) REFERENCES territories(id),
    dimension VARCHAR(50), -- 'economic', 'social', 'territorial', 'environmental'
    analysis_type VARCHAR(50), -- 'diagnostic', 'trend', 'comparison', 'recommendation'
    content TEXT, -- An√°lise em texto
    metadata JSONB, -- Metadados da an√°lise
    embedding VECTOR(1536), -- Vetor para RAG (pgvector)
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**Impacto da Falta:**
- ‚ùå Dashboard n√£o tem an√°lises prontas
- ‚ùå Usu√°rio precisa esperar IA gerar an√°lise toda vez
- ‚ùå Sem RAG (busca sem√¢ntica)
- ‚ùå Sem cache de an√°lises
- ‚ùå Sem aprendizado cont√≠nuo

**Quantidade Necess√°ria:**
```
140 territ√≥rios √ó 4 dimens√µes √ó 4 tipos de an√°lise = 2.240 an√°lises
```

---

#### **indicator_metadata (0 registros) ‚ùå CR√çTICO**

**Prop√≥sito:**
- Explicar **significado** de cada indicador
- Mostrar **tooltips** no dashboard
- Fornecer **contexto** para interpreta√ß√£o
- Indicar **fontes** e **metodologia**

**Schema Esperado:**
```sql
CREATE TABLE indicator_metadata (
    id SERIAL PRIMARY KEY,
    indicator_code VARCHAR(50) UNIQUE, -- 'gdp', 'idhm', 'area_km2', etc.
    dimension VARCHAR(50), -- 'economic', 'social', etc.
    name VARCHAR(200), -- Nome completo
    description TEXT, -- Descri√ß√£o detalhada
    unit VARCHAR(50), -- Unidade de medida
    source VARCHAR(200), -- Fonte dos dados
    methodology TEXT, -- Como √© calculado
    interpretation_guide TEXT, -- Como interpretar
    good_range JSONB, -- Faixa considerada boa
    alert_range JSONB, -- Faixa de alerta
    created_at TIMESTAMP DEFAULT NOW()
);
```

**Impacto da Falta:**
- ‚ùå Usu√°rio n√£o entende o que cada indicador significa
- ‚ùå Sem tooltips explicativos no dashboard
- ‚ùå Sem contexto para interpreta√ß√£o
- ‚ùå Dashboard fica "cru" e pouco did√°tico

**Quantidade Necess√°ria:**
```
~50-80 indicadores √∫nicos (todos os campos das 4 dimens√µes)
```

---

## üéØ Estrat√©gias de Solu√ß√£o

### **ESTRAT√âGIA 1: Popular indicator_metadata**

#### **Op√ß√£o A: Cria√ß√£o Manual Estruturada (RECOMENDADA)**

**Vantagens:**
- ‚úÖ Controle total sobre qualidade
- ‚úÖ Precis√£o t√©cnica garantida
- ‚úÖ Pode ser revisado por especialistas

**Processo:**
1. Listar todos os indicadores das 4 dimens√µes
2. Para cada indicador, criar registro com:
   - Nome completo
   - Descri√ß√£o clara
   - Unidade de medida
   - Fonte (IBGE, SICONFI, etc.)
   - Metodologia de c√°lculo
   - Guia de interpreta√ß√£o
   - Faixas de refer√™ncia

**Tempo estimado:** 4-6 horas (50-80 indicadores)

**Exemplo:**
```json
{
  "indicator_code": "idhm",
  "dimension": "social",
  "name": "√çndice de Desenvolvimento Humano Municipal",
  "description": "Medida composta que avalia o desenvolvimento humano em tr√™s dimens√µes: longevidade, educa√ß√£o e renda.",
  "unit": "√≠ndice (0-1)",
  "source": "IBGE - Censo Demogr√°fico",
  "methodology": "M√©dia geom√©trica dos √≠ndices de longevidade, educa√ß√£o e renda, normalizados entre 0 e 1.",
  "interpretation_guide": "0-0.499: Muito Baixo | 0.500-0.599: Baixo | 0.600-0.699: M√©dio | 0.700-0.799: Alto | 0.800-1.000: Muito Alto",
  "good_range": {"min": 0.700, "max": 1.000},
  "alert_range": {"min": 0.000, "max": 0.599}
}
```

---

#### **Op√ß√£o B: Gera√ß√£o Semi-Autom√°tica com IA**

**Vantagens:**
- ‚úÖ Mais r√°pido (1-2 horas)
- ‚úÖ Cobertura completa garantida
- ‚ö†Ô∏è Precisa revis√£o humana

**Processo:**
1. Extrair lista de indicadores do schema
2. Usar GPT-4 para gerar metadados
3. Revisar e ajustar manualmente
4. Inserir no banco

**Script:**
```python
import openai

indicators = [
    {"code": "idhm", "dimension": "social"},
    {"code": "gdp", "dimension": "economic"},
    # ... todos os indicadores
]

for indicator in indicators:
    prompt = f"""
    Crie metadados completos para o indicador brasileiro:
    C√≥digo: {indicator['code']}
    Dimens√£o: {indicator['dimension']}
    
    Retorne JSON com:
    - name: nome completo em portugu√™s
    - description: descri√ß√£o clara (2-3 frases)
    - unit: unidade de medida
    - source: fonte oficial (IBGE, SICONFI, etc.)
    - methodology: como √© calculado
    - interpretation_guide: como interpretar valores
    - good_range: faixa considerada boa
    - alert_range: faixa de alerta
    """
    
    response = openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    
    metadata = json.loads(response.choices[0].message.content)
    # Inserir no banco
```

---

### **ESTRAT√âGIA 2: Popular knowledge_base**

#### **Op√ß√£o A: Gera√ß√£o em Lote via n8n (RECOMENDADA)**

**Vantagens:**
- ‚úÖ Usa agentes especialistas j√° criados
- ‚úÖ An√°lises consistentes e padronizadas
- ‚úÖ Pode ser reexecutado facilmente
- ‚úÖ Integrado com workflow existente

**Processo:**
1. Criar workflow n8n "Batch Analysis Generator"
2. Para cada territ√≥rio (140):
   - Chamar agente ECON
   - Chamar agente SOCIAL
   - Chamar agente TERRA
   - Chamar agente AMBIENT
3. Salvar an√°lises na knowledge_base
4. Gerar embeddings para RAG

**Tempo estimado:** 
- Execu√ß√£o: 2-3 horas (autom√°tico)
- Setup: 1 hora

**Custo estimado:**
```
140 territ√≥rios √ó 4 dimens√µes √ó $0.001 = $0.56
```

**Workflow n8n:**
```
[Schedule Trigger]
    ‚Üì
[PostgreSQL: Get Territories]
    ‚Üì
[Loop: For Each Territory]
    ‚Üì
    ‚îú‚îÄ‚Üí [HTTP: Call ECON Agent] ‚Üí [Save to KB]
    ‚îú‚îÄ‚Üí [HTTP: Call SOCIAL Agent] ‚Üí [Save to KB]
    ‚îú‚îÄ‚Üí [HTTP: Call TERRA Agent] ‚Üí [Save to KB]
    ‚îî‚îÄ‚Üí [HTTP: Call AMBIENT Agent] ‚Üí [Save to KB]
```

---

#### **Op√ß√£o B: Gera√ß√£o Sob Demanda (Atual)**

**Vantagens:**
- ‚úÖ An√°lises sempre atualizadas
- ‚úÖ Sem custo inicial
- ‚ö†Ô∏è Usu√°rio espera 6-8 segundos

**Desvantagens:**
- ‚ùå Experi√™ncia de usu√°rio pior
- ‚ùå Sem cache
- ‚ùå Sem RAG

**Recomenda√ß√£o:** Usar como fallback se an√°lise n√£o existir no cache.

---

#### **Op√ß√£o C: Gera√ß√£o H√≠brida (MELHOR)**

**Combinar:**
1. **Pr√©-gerar** an√°lises para os 20 munic√≠pios mais importantes
2. **Gerar sob demanda** para os demais
3. **Cachear** todas as an√°lises geradas
4. **Atualizar** periodicamente (mensal)

**Vantagens:**
- ‚úÖ Melhor custo-benef√≠cio
- ‚úÖ Boa experi√™ncia para casos comuns
- ‚úÖ Cobertura completa eventual

---

## üìä Prioriza√ß√£o

### **Prioridade ALTA (Fazer Agora)**

1. **Popular indicator_metadata** (Op√ß√£o A: Manual)
   - Tempo: 4-6 horas
   - Impacto: Alto (UX do dashboard)
   - Complexidade: Baixa

2. **Pr√©-gerar an√°lises para top 20 munic√≠pios** (Op√ß√£o C)
   - Tempo: 30 minutos
   - Custo: $0.08
   - Impacto: M√©dio (demonstra√ß√£o)

---

### **Prioridade M√âDIA (Esta Semana)**

3. **Criar workflow de gera√ß√£o em lote** (Op√ß√£o A)
   - Tempo: 1 hora setup + 3 horas execu√ß√£o
   - Custo: $0.56
   - Impacto: Alto (experi√™ncia completa)

4. **Implementar sistema de cache**
   - Tempo: 2 horas
   - Impacto: Alto (performance)

---

### **Prioridade BAIXA (Pr√≥xima Semana)**

5. **Implementar RAG com embeddings**
   - Tempo: 4-6 horas
   - Impacto: M√©dio (busca sem√¢ntica)

6. **Sistema de atualiza√ß√£o peri√≥dica**
   - Tempo: 2 horas
   - Impacto: Baixo (manuten√ß√£o)

---

## üîß Scripts Prontos para Usar

### **Script 1: Extrair Lista de Indicadores**

```python
# extract_indicators.py
import json

# Ler schemas das tabelas
indicators = []

# Econ√¥micos
economic = {
    "gdp": {"name": "PIB", "unit": "milh√µes R$"},
    "gdp_per_capita": {"name": "PIB per capita", "unit": "R$"},
    "employment_rate": {"name": "Taxa de emprego", "unit": "%"},
    "revenue": {"name": "Receita total", "unit": "R$"}
}

# Sociais
social = {
    "idhm": {"name": "IDH-M", "unit": "√≠ndice"},
    "population": {"name": "Popula√ß√£o", "unit": "habitantes"},
    "literacy_rate": {"name": "Taxa de alfabetiza√ß√£o", "unit": "%"},
    "income_per_capita": {"name": "Renda per capita", "unit": "R$"}
}

# ... territorial e ambiental

# Salvar
with open('indicators_list.json', 'w') as f:
    json.dump(indicators, f, indent=2, ensure_ascii=False)
```

---

### **Script 2: Gerar Metadados com IA**

```python
# generate_metadata.py
import json
import os
from openai import OpenAI

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

with open('indicators_list.json') as f:
    indicators = json.load(f)

metadata_list = []

for indicator in indicators:
    prompt = f"""
    Crie metadados completos para este indicador brasileiro:
    
    C√≥digo: {indicator['code']}
    Nome: {indicator['name']}
    Dimens√£o: {indicator['dimension']}
    
    Retorne APENAS um JSON v√°lido com:
    {{
      "indicator_code": "{indicator['code']}",
      "dimension": "{indicator['dimension']}",
      "name": "nome completo em portugu√™s",
      "description": "descri√ß√£o clara em 2-3 frases",
      "unit": "unidade de medida",
      "source": "fonte oficial (IBGE, SICONFI, DataSUS, INEP, INPE)",
      "methodology": "como √© calculado",
      "interpretation_guide": "como interpretar valores",
      "good_range": {{"min": X, "max": Y}},
      "alert_range": {{"min": X, "max": Y}}
    }}
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    metadata = json.loads(response.choices[0].message.content)
    metadata_list.append(metadata)
    
    print(f"‚úì {indicator['code']}")

# Salvar
with open('indicator_metadata.json', 'w') as f:
    json.dump(metadata_list, f, indent=2, ensure_ascii=False)

print(f"\n‚úì {len(metadata_list)} metadados gerados")
```

---

### **Script 3: Inserir Metadados no Banco**

```python
# insert_metadata.py
import json
import psycopg2
import os

# Conectar
conn = psycopg2.connect(os.getenv('DATABASE_URL'))
cur = conn.cursor()

# Ler metadados
with open('indicator_metadata.json') as f:
    metadata_list = json.load(f)

# Inserir
for metadata in metadata_list:
    cur.execute("""
        INSERT INTO indicator_metadata (
            indicator_code, dimension, name, description, unit,
            source, methodology, interpretation_guide, 
            good_range, alert_range
        ) VALUES (
            %(indicator_code)s, %(dimension)s, %(name)s, %(description)s, %(unit)s,
            %(source)s, %(methodology)s, %(interpretation_guide)s,
            %(good_range)s, %(alert_range)s
        )
        ON CONFLICT (indicator_code) DO UPDATE SET
            name = EXCLUDED.name,
            description = EXCLUDED.description,
            unit = EXCLUDED.unit,
            source = EXCLUDED.source,
            methodology = EXCLUDED.methodology,
            interpretation_guide = EXCLUDED.interpretation_guide,
            good_range = EXCLUDED.good_range,
            alert_range = EXCLUDED.alert_range
    """, metadata)
    
    print(f"‚úì {metadata['indicator_code']}")

conn.commit()
print(f"\n‚úì {len(metadata_list)} metadados inseridos")
```

---

### **Script 4: Gerar An√°lises em Lote**

```python
# batch_generate_analyses.py
import requests
import psycopg2
import os
import time

# Conectar
conn = psycopg2.connect(os.getenv('DATABASE_URL'))
cur = conn.cursor()

# Buscar territ√≥rios
cur.execute("SELECT id, name FROM territories WHERE type = 'Munic√≠pio' LIMIT 20")
territories = cur.fetchall()

# Agentes
agents = {
    'economic': 'https://galactic-ai.app.n8n.cloud/webhook/agent-econ',
    'social': 'https://galactic-ai.app.n8n.cloud/webhook/agent-social',
    'territorial': 'https://galactic-ai.app.n8n.cloud/webhook/agent-terra',
    'environmental': 'https://galactic-ai.app.n8n.cloud/webhook/agent-ambient'
}

for territory_id, territory_name in territories:
    print(f"\n=== {territory_name} ===")
    
    for dimension, webhook_url in agents.items():
        print(f"  {dimension}...", end=" ")
        
        # Chamar agente
        response = requests.post(webhook_url, json={
            'territory_id': territory_id,
            'analysis_type': 'diagnostic'
        })
        
        if response.status_code == 200:
            analysis = response.json()
            
            # Salvar na knowledge_base
            cur.execute("""
                INSERT INTO knowledge_base (
                    territory_id, dimension, analysis_type, content, metadata
                ) VALUES (%s, %s, %s, %s, %s)
            """, (
                territory_id,
                dimension,
                'diagnostic',
                analysis['analysis'],
                json.dumps(analysis.get('metadata', {}))
            ))
            
            conn.commit()
            print("‚úì")
        else:
            print("‚úó")
        
        time.sleep(2)  # Rate limit

print(f"\n‚úì An√°lises geradas para {len(territories)} territ√≥rios")
```

---

## üìù Resumo Executivo

### **Situa√ß√£o Atual:**
- ‚úÖ Dados de indicadores: **OK** (3.914 registros)
- ‚ùå Knowledge base: **VAZIA** (0 an√°lises)
- ‚ùå Metadados: **VAZIOS** (0 indicadores)

### **Impacto:**
- ‚ö†Ô∏è Dashboard funciona mas sem contexto
- ‚ö†Ô∏è Usu√°rio n√£o entende indicadores
- ‚ö†Ô∏è Sem an√°lises prontas (espera 6-8s)

### **Solu√ß√£o Recomendada:**
1. **Hoje:** Popular indicator_metadata (manual, 4-6h)
2. **Hoje:** Gerar an√°lises top 20 munic√≠pios (autom√°tico, 30min)
3. **Esta semana:** Workflow de gera√ß√£o em lote (1h setup + 3h exec)

### **Custo Total:**
- Tempo: ~10 horas
- Dinheiro: ~$0.60 (OpenAI)

### **Resultado:**
- ‚úÖ Dashboard completo e did√°tico
- ‚úÖ An√°lises prontas para demonstra√ß√£o
- ‚úÖ Sistema escal√°vel e sustent√°vel

---

**Framework de Intelig√™ncia Territorial V6.0**  
Henrique M. Ribeiro  
23 de novembro de 2025
