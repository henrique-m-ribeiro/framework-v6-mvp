# Guia de Implementa√ß√£o: Roteador Inteligente Multi-LLM no n8n

Henrique, conforme solicitado, preparei um guia completo para voc√™ criar manualmente o n√≥ do **Roteador Inteligente** no n8n. Este guia oferece a flexibilidade de usar diferentes modelos de LLM (OpenAI, Google Gemini, Anthropic Claude e Deepseek), preparando nosso sistema para o futuro.

---

## üéØ Objetivo

Criar um n√≥ no n8n que receba uma pergunta do usu√°rio e a classifique em uma das quatro dimens√µes (**econ**, **social**, **terra**, **ambient**), retornando apenas o c√≥digo da dimens√£o.

## üß† O Prompt (A L√≥gica Central)

O cora√ß√£o do nosso roteador √© o prompt do sistema. Ele ser√° praticamente o mesmo para todos os modelos. Apenas o local onde voc√™ o insere muda.

```text
Voc√™ √© um roteador inteligente para um sistema de an√°lise territorial.

Sua tarefa √© classificar a pergunta do usu√°rio em UMA das 4 dimens√µes:

1.  **econ** (Econ√¥mica): PIB, emprego, renda, setores econ√¥micos, empresas, com√©rcio, ind√∫stria, servi√ßos
2.  **social** (Social): Popula√ß√£o, educa√ß√£o, sa√∫de, seguran√ßa, assist√™ncia social, cultura, esporte
3.  **terra** (Territorial): Uso do solo, infraestrutura urbana, transporte, habita√ß√£o, saneamento, planejamento urbano
4.  **ambient** (Ambiental): Meio ambiente, recursos naturais, polui√ß√£o, √°reas protegidas, clima, biodiversidade

RESPONDA APENAS COM O C√ìDIGO DA DIMENS√ÉO (econ, social, terra ou ambient).
```

--- 

## üõ†Ô∏è Guia Passo a Passo: Configurando o N√≥

Primeiro, delete o n√≥ "OpenAI - Roteador Inteligente" que n√£o est√° funcionando no seu workflow. Em seguida, adicione um novo n√≥ e escolha uma das op√ß√µes abaixo.

### ‚úÖ Op√ß√£o 1: OpenAI (Recomendado para Iniciar)

1.  **Adicionar N√≥:** Busque e adicione o n√≥ **OpenAI**.
2.  **Credenciais:** Conecte sua credencial da OpenAI.
3.  **Configura√ß√£o:**
    *   **Resource:** `Text`
    *   **Operation:** `Generate a Chat Completion`
    *   **Model:** `gpt-4o-mini` (√≥timo custo-benef√≠cio)
    *   **Messages:**
        *   Clique em **"Add Message"**.
        *   **Item 1 (System):**
            *   **Role:** `System`
            *   **Content:** Cole o prompt do sistema (acima).
        *   **Item 2 (User):**
            *   **Role:** `User`
            *   **Content (Expression):** `{{ $("Webhook - Recebe Requisi√ß√£o").first().json.body.question }}`
    *   **Options (Opcional, mas recomendado):**
        *   **Temperature:** `0.1` (para respostas consistentes)
        *   **Max Tokens:** `10` (s√≥ precisamos de uma palavra)
    *   **Simplify Output:** `Ativado` (retorna apenas o texto da resposta)

###  alternativa Op√ß√£o 2: Google Gemini

1.  **Adicionar N√≥:** Busque e adicione o n√≥ **Google Gemini**.
2.  **Credenciais:** Conecte sua credencial do Google.
3.  **Configura√ß√£o:**
    *   **Resource:** `Chat`
    *   **Operation:** `Send Message`
    *   **Model:** `gemini-1.5-flash-latest` (r√°pido e eficiente)
    *   **Message:**
        *   **Role:** `User`
        *   **Text (Expression):**
            ```
            SYSTEM: [COLE O PROMPT DO SISTEMA AQUI]
            
            USER: {{ $("Webhook - Recebe Requisi√ß√£o").first().json.body.question }}
            ```
    *   **Options (Opcional):**
        *   **Temperature:** `0.1`
        *   **Max Output Tokens:** `10`

###  alternativa Op√ß√£o 3: Anthropic Claude

1.  **Adicionar N√≥:** Busque e adicione o n√≥ **Anthropic**.
2.  **Credenciais:** Conecte sua credencial da Anthropic.
3.  **Configura√ß√£o:**
    *   **Resource:** `Chat`
    *   **Operation:** `Send Message`
    *   **Model:** `claude-3-haiku-20240307` (mais r√°pido da fam√≠lia Claude)
    *   **System Prompt:** Cole o prompt do sistema (acima).
    *   **Messages:**
        *   **Role:** `User`
        *   **Content (Expression):** `{{ $("Webhook - Recebe Requisi√ß√£o").first().json.body.question }}`
    *   **Options (Opcional):**
        *   **Temperature:** `0.1`
        *   **Max Tokens:** `10`

### üöÄ Op√ß√£o 4: Deepseek (via HTTP Request)

Esta √© a op√ß√£o mais flex√≠vel, pois funciona para qualquer modelo que tenha uma API compat√≠vel com OpenAI.

1.  **Adicionar N√≥:** Busque e adicione o n√≥ **HTTP Request**.
2.  **Credenciais:** Nenhuma (a chave vai no Header).
3.  **Configura√ß√£o:**
    *   **Method:** `POST`
    *   **URL:** `https://api.deepseek.com/v1/chat/completions`
    *   **Authentication:** `None`
    *   **Headers:**
        *   Clique em **"Add Header"**.
        *   **Name 1:** `Authorization`
        *   **Value 1:** `Bearer [SUA_CHAVE_API_DEEPSEEK]`
        *   **Name 2:** `Content-Type`
        *   **Value 2:** `application/json`
    *   **Body Content Type:** `JSON`
    *   **Body (Expression):**
        ```json
        {
          "model": "deepseek-chat",
          "messages": [
            {
              "role": "system",
              "content": "[COLE O PROMPT DO SISTEMA AQUI]"
            },
            {
              "role": "user",
              "content": "{{ $(\"Webhook - Recebe Requisi√ß√£o\").first().json.body.question }}"
            }
          ],
          "temperature": 0.1,
          "max_tokens": 10
        }
        ```

--- 

## üîå Passo Final: Atualizar o N√≥ Switch

O n√≥ **Switch** precisa saber onde ler a resposta do LLM. O caminho muda dependendo do n√≥ que voc√™ usou.

1.  Clique no n√≥ **Switch**.
2.  Para cada uma das 4 regras (econ, social, terra, ambient), atualize o campo **Value 1** com a express√£o correta:

    *   **Se usou OpenAI (com Simplify Output):**
        `{{ $json.message.toLowerCase().trim() }}`

    *   **Se usou Google Gemini:**
        `{{ $json.candidates[0].content.parts[0].text.toLowerCase().trim() }}`

    *   **Se usou Anthropic Claude:**
        `{{ $json.content[0].text.toLowerCase().trim() }}`

    *   **Se usou Deepseek (HTTP Request):**
        `{{ $json.choices[0].message.content.toLowerCase().trim() }}`

---

## üí° Recomenda√ß√£o

Comece com a **Op√ß√£o 1 (OpenAI)**. √â a mais direta e bem documentada no n8n. Depois que o workflow estiver funcionando, voc√™ pode duplic√°-lo e experimentar as outras op√ß√µes para comparar performance e custo.

Estou √† disposi√ß√£o para ajudar em cada passo da configura√ß√£o. Apenas me diga qual op√ß√£o voc√™ escolheu e podemos configurar juntos!
