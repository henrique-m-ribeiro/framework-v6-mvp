# ğŸ§  PLANO DE IMPLEMENTAÃ‡ÃƒO: RAG no Agente ECON

**Framework de InteligÃªncia Territorial V6.0**  
**SessÃ£o:** #6  
**Data:** 26 de novembro de 2025  
**Agente:** ECON (Especialista EconÃ´mico)

---

## ğŸ¯ OBJETIVO ESTRATÃ‰GICO

Implementar um sistema de **Retrieval-Augmented Generation (RAG)** no Agente ECON para:

âœ… **Enriquecer anÃ¡lises** com conhecimento especializado de fontes acadÃªmicas  
âœ… **Reduzir alucinaÃ§Ãµes** da LLM com contexto factual  
âœ… **Evoluir continuamente** atravÃ©s de memÃ³ria de longo prazo  
âœ… **Fundamentar insights** com referÃªncias bibliogrÃ¡ficas  
âœ… **Escalar conhecimento** sem re-treinar modelos

---

## ğŸ“Š ARQUITETURA DO RAG

### VisÃ£o Geral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORKFLOW ECON                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  1. Webhook Recebe Tarefa                              â”‚
â”‚           â†“                                             â”‚
â”‚  2. Consultar Dados PostgreSQL                         â”‚
â”‚           â†“                                             â”‚
â”‚  3. Preparar Contexto para LLM                         â”‚
â”‚           â†“                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  4. BUSCA RAG (NOVO)                  â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            â”‚
â”‚  â”‚  â”‚ a) Gerar embedding da query     â”‚  â”‚            â”‚
â”‚  â”‚  â”‚ b) Buscar similaridade vetorial â”‚  â”‚            â”‚
â”‚  â”‚  â”‚ c) Recuperar top-k documentos   â”‚  â”‚            â”‚
â”‚  â”‚  â”‚ d) Adicionar ao contexto        â”‚  â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â†“                                             â”‚
â”‚  5. Gerar AnÃ¡lise com OpenAI (contexto enriquecido)   â”‚
â”‚           â†“                                             â”‚
â”‚  6. Estruturar Resposta                                â”‚
â”‚           â†“                                             â”‚
â”‚  7. Salvar AnÃ¡lise no PostgreSQL                       â”‚
â”‚           â†“                                             â”‚
â”‚  8. Preparar Resposta do Webhook                       â”‚
â”‚           â†“                                             â”‚
â”‚  9. Respond to Webhook                                 â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BANCO DE DADOS POSTGRESQL                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Tabela: agent_econ_memory                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ id (PK)                                       â”‚    â”‚
â”‚  â”‚ document_title                                â”‚    â”‚
â”‚  â”‚ document_source                               â”‚    â”‚
â”‚  â”‚ document_type (academic_paper, report, etc.)  â”‚    â”‚
â”‚  â”‚ content_text                                  â”‚    â”‚
â”‚  â”‚ content_embedding (vector)                    â”‚    â”‚
â”‚  â”‚ metadata (JSONB)                              â”‚    â”‚
â”‚  â”‚ created_at                                    â”‚    â”‚
â”‚  â”‚ updated_at                                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â”‚  Ãndice: vector_similarity (pgvector)                  â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ ETAPAS DE IMPLEMENTAÃ‡ÃƒO

### **ETAPA 1: PreparaÃ§Ã£o da Infraestrutura** ğŸ—ï¸

**DuraÃ§Ã£o estimada:** 30-45 minutos  
**Tokens estimados:** 8.000 tokens

#### 1.1. Instalar ExtensÃ£o pgvector no PostgreSQL

**AÃ§Ã£o:**
```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

**VerificaÃ§Ã£o:**
```sql
SELECT * FROM pg_extension WHERE extname = 'vector';
```

#### 1.2. Criar Tabela de MemÃ³ria

**Script SQL:**
```sql
CREATE TABLE IF NOT EXISTS agent_econ_memory (
    id SERIAL PRIMARY KEY,
    document_title VARCHAR(500) NOT NULL,
    document_source VARCHAR(500) NOT NULL,
    document_type VARCHAR(100) NOT NULL,
    content_text TEXT NOT NULL,
    content_embedding vector(1536),  -- OpenAI text-embedding-3-small
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Ãndice para busca por similaridade
CREATE INDEX IF NOT EXISTS agent_econ_memory_embedding_idx 
ON agent_econ_memory 
USING ivfflat (content_embedding vector_cosine_ops)
WITH (lists = 100);

-- Ãndice para busca por tipo de documento
CREATE INDEX IF NOT EXISTS agent_econ_memory_type_idx 
ON agent_econ_memory (document_type);

-- Ãndice para busca por fonte
CREATE INDEX IF NOT EXISTS agent_econ_memory_source_idx 
ON agent_econ_memory (document_source);
```

#### 1.3. Criar FunÃ§Ã£o de Busca por Similaridade

**Script SQL:**
```sql
CREATE OR REPLACE FUNCTION search_similar_documents(
    query_embedding vector(1536),
    match_threshold float DEFAULT 0.7,
    match_count int DEFAULT 5
)
RETURNS TABLE (
    id int,
    document_title varchar,
    document_source varchar,
    document_type varchar,
    content_text text,
    similarity float,
    metadata jsonb
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    SELECT
        m.id,
        m.document_title,
        m.document_source,
        m.document_type,
        m.content_text,
        1 - (m.content_embedding <=> query_embedding) as similarity,
        m.metadata
    FROM agent_econ_memory m
    WHERE 1 - (m.content_embedding <=> query_embedding) > match_threshold
    ORDER BY m.content_embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

**Tokens desta etapa:** ~8.000 tokens

---

### **ETAPA 2: Popular MemÃ³ria com Documentos de ReferÃªncia** ğŸ“š

**DuraÃ§Ã£o estimada:** 1-2 horas  
**Tokens estimados:** 12.000 tokens

#### 2.1. Selecionar Documentos de ReferÃªncia

**CritÃ©rios de seleÃ§Ã£o:**
- âœ… Artigos acadÃªmicos de economia regional
- âœ… PublicaÃ§Ãµes do IPEA sobre desenvolvimento econÃ´mico
- âœ… RelatÃ³rios do IBGE sobre indicadores econÃ´micos
- âœ… Estudos sobre economia do Tocantins

**Documentos sugeridos (1-2 para MVP):**

1. **"Desenvolvimento EconÃ´mico Regional no Brasil"** (IPEA)
   - Fonte: https://www.ipea.gov.br
   - Tipo: academic_paper
   - RelevÃ¢ncia: Alta (contexto nacional e regional)

2. **"Indicadores EconÃ´micos Municipais: Metodologia e AplicaÃ§Ãµes"** (IBGE)
   - Fonte: https://www.ibge.gov.br
   - Tipo: technical_report
   - RelevÃ¢ncia: Alta (metodologia de anÃ¡lise)

#### 2.2. Processar Documentos

**Workflow de processamento:**

```
1. Download do PDF
   â†“
2. Extrair texto (poppler-utils)
   â†“
3. Limpar e normalizar
   â†“
4. Chunking (dividir em blocos de ~500 tokens)
   â†“
5. Gerar embeddings (OpenAI text-embedding-3-small)
   â†“
6. Salvar no PostgreSQL
```

**Script Python (exemplo):**
```python
import os
from openai import OpenAI
import psycopg2
from pdf2image import convert_from_path
import pytesseract

client = OpenAI()  # API key jÃ¡ configurada

def process_document(pdf_path, title, source, doc_type):
    # 1. Extrair texto do PDF
    text = extract_text_from_pdf(pdf_path)
    
    # 2. Dividir em chunks
    chunks = chunk_text(text, max_tokens=500)
    
    # 3. Gerar embeddings e salvar
    conn = psycopg2.connect(os.getenv('DATABASE_URL'))
    cur = conn.cursor()
    
    for i, chunk in enumerate(chunks):
        # Gerar embedding
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=chunk
        )
        embedding = response.data[0].embedding
        
        # Salvar no banco
        cur.execute("""
            INSERT INTO agent_econ_memory 
            (document_title, document_source, document_type, 
             content_text, content_embedding, metadata)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (
            f"{title} (Parte {i+1})",
            source,
            doc_type,
            chunk,
            embedding,
            {'chunk_index': i, 'total_chunks': len(chunks)}
        ))
    
    conn.commit()
    cur.close()
    conn.close()
    
    print(f"âœ… Documento '{title}' processado: {len(chunks)} chunks")

def extract_text_from_pdf(pdf_path):
    # ImplementaÃ§Ã£o de extraÃ§Ã£o de texto
    pass

def chunk_text(text, max_tokens=500):
    # ImplementaÃ§Ã£o de chunking
    pass
```

**Tokens desta etapa:** ~12.000 tokens

---

### **ETAPA 3: Criar NÃ³ de Busca RAG no Workflow** ğŸ”

**DuraÃ§Ã£o estimada:** 45-60 minutos  
**Tokens estimados:** 10.000 tokens

#### 3.1. Adicionar NÃ³ "Buscar Conhecimento RAG"

**PosiÃ§Ã£o no workflow:**
- **ApÃ³s:** "Preparar Contexto para LLM"
- **Antes:** "Gerar AnÃ¡lise com OpenAI"

**Tipo de nÃ³:** Code (JavaScript)

**CÃ³digo JavaScript:**
```javascript
// ===============================================
// NÃ“: BUSCAR CONHECIMENTO RAG
// Framework de InteligÃªncia Territorial V6.0
// ===============================================
// FUNÃ‡ÃƒO: Buscar documentos relevantes na memÃ³ria
//         do agente para enriquecer o contexto
// ===============================================

const { OpenAI } = require('openai');
const { Client } = require('pg');

// 1. EXTRAIR DADOS DO NÃ“ ANTERIOR
const contextData = $input.first().json;
const territoryName = contextData.territory_name;
const focusAreas = contextData.parameters.focus_areas.join(', ');

// 2. CONSTRUIR QUERY PARA RAG
const ragQuery = `
AnÃ¡lise econÃ´mica de ${territoryName} focando em: ${focusAreas}.
Contexto: indicadores econÃ´micos, PIB, emprego, renda, setores produtivos.
`;

console.log('ğŸ” Query RAG:', ragQuery);

// 3. GERAR EMBEDDING DA QUERY
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

const embeddingResponse = await openai.embeddings.create({
  model: 'text-embedding-3-small',
  input: ragQuery
});

const queryEmbedding = embeddingResponse.data[0].embedding;
console.log('âœ… Embedding gerado:', queryEmbedding.length, 'dimensÃµes');

// 4. BUSCAR DOCUMENTOS SIMILARES NO POSTGRESQL
const client = new Client({
  connectionString: process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false }
});

await client.connect();

const result = await client.query(`
  SELECT * FROM search_similar_documents(
    $1::vector,
    0.7,  -- threshold de similaridade
    3     -- top-3 documentos
  )
`, [[queryEmbedding]]);

await client.end();

console.log('ğŸ“š Documentos encontrados:', result.rows.length);

// 5. FORMATAR CONTEXTO RAG
let ragContext = '';

if (result.rows.length > 0) {
  ragContext = '\n\n## ğŸ“š CONHECIMENTO DE REFERÃŠNCIA\n\n';
  
  result.rows.forEach((doc, index) => {
    ragContext += `### ReferÃªncia ${index + 1}: ${doc.document_title}\n`;
    ragContext += `**Fonte:** ${doc.document_source}\n`;
    ragContext += `**Similaridade:** ${(doc.similarity * 100).toFixed(1)}%\n\n`;
    ragContext += `${doc.content_text}\n\n`;
    ragContext += `---\n\n`;
  });
  
  console.log('âœ… Contexto RAG construÃ­do:', ragContext.length, 'caracteres');
} else {
  console.log('âš ï¸ Nenhum documento relevante encontrado');
  ragContext = '\n\n## â„¹ï¸ Nenhuma referÃªncia especÃ­fica encontrada na base de conhecimento.\n\n';
}

// 6. RETORNAR DADOS ENRIQUECIDOS
return {
  ...contextData,
  rag_context: ragContext,
  rag_documents_found: result.rows.length,
  rag_documents: result.rows.map(doc => ({
    title: doc.document_title,
    source: doc.document_source,
    similarity: doc.similarity
  }))
};
```

#### 3.2. Atualizar NÃ³ "Preparar Contexto para LLM"

**ModificaÃ§Ã£o:**
Incluir o `rag_context` no prompt enviado para a OpenAI.

**Antes:**
```javascript
const prompt = `
VocÃª Ã© um especialista econÃ´mico...

## DADOS DO TERRITÃ“RIO
${territoryData}

## TAREFA
Analise os dados e gere insights...
`;
```

**Depois:**
```javascript
const prompt = `
VocÃª Ã© um especialista econÃ´mico...

## DADOS DO TERRITÃ“RIO
${territoryData}

${ragContext}  // â† NOVO: Contexto RAG

## TAREFA
Analise os dados, considerando as referÃªncias fornecidas, e gere insights...
`;
```

**Tokens desta etapa:** ~10.000 tokens

---

### **ETAPA 4: Testar e Validar** ğŸ§ª

**DuraÃ§Ã£o estimada:** 30-45 minutos  
**Tokens estimados:** 8.000 tokens

#### 4.1. Teste BÃ¡sico (Sem RAG)

**Objetivo:** Estabelecer baseline

**POST Request:**
```json
{
  "task_id": "test-rag-baseline",
  "agent_name": "ECON",
  "territory_id": "1721000",
  "territory_name": "Palmas",
  "territory_type": "municipality",
  "analysis_type": "economic",
  "parameters": {
    "focus_areas": ["PIB", "emprego"],
    "time_period": "2019-2023",
    "detail_level": "comprehensive"
  }
}
```

**Resultado esperado:**
- AnÃ¡lise sem referÃªncias bibliogrÃ¡ficas
- Tempo de processamento: ~30-40s

#### 4.2. Teste com RAG

**Objetivo:** Validar enriquecimento

**POST Request:** (mesmo do teste bÃ¡sico)

**Resultado esperado:**
- AnÃ¡lise com referÃªncias bibliogrÃ¡ficas
- SeÃ§Ã£o "Conhecimento de ReferÃªncia" no contexto
- Insights mais fundamentados
- Tempo de processamento: ~35-45s (overhead de ~5-10s)

#### 4.3. ValidaÃ§Ã£o de Qualidade

**CritÃ©rios:**
- âœ… Documentos relevantes sÃ£o recuperados (similaridade > 70%)
- âœ… Contexto RAG Ã© incluÃ­do no prompt
- âœ… AnÃ¡lise menciona ou reflete o conhecimento recuperado
- âœ… Tempo de processamento aceitÃ¡vel (< 60s)
- âœ… Sem erros no workflow

**Tokens desta etapa:** ~8.000 tokens

---

### **ETAPA 5: DocumentaÃ§Ã£o** ğŸ“

**DuraÃ§Ã£o estimada:** 45-60 minutos  
**Tokens estimados:** 10.000 tokens

#### 5.1. Documentos a Criar

1. **IMPLEMENTACAO_RAG_ECON.md**
   - Arquitetura detalhada
   - Scripts SQL completos
   - CÃ³digo JavaScript completo
   - Exemplos de uso

2. **GUIA_POPULAR_MEMORIA_ECON.md**
   - Como adicionar novos documentos
   - CritÃ©rios de seleÃ§Ã£o
   - Script Python de processamento

3. **TESTE_RAG_ECON.md**
   - Casos de teste
   - Resultados esperados
   - ComparaÃ§Ã£o antes/depois

4. **FAQ_RAG_ECON.md**
   - Perguntas frequentes
   - Troubleshooting
   - OtimizaÃ§Ãµes

**Tokens desta etapa:** ~10.000 tokens

---

### **ETAPA 6: DiÃ¡rio Reflexivo** ğŸ“”

**DuraÃ§Ã£o estimada:** 30 minutos  
**Tokens estimados:** 5.000 tokens

#### ConteÃºdo

- ReflexÃ£o sobre a implementaÃ§Ã£o
- Desafios encontrados
- Aprendizados
- PrÃ³ximos passos
- ImplicaÃ§Ãµes para o projeto

**Tokens desta etapa:** ~5.000 tokens

---

## ğŸ“Š RESUMO DE TOKENS

| Etapa | DescriÃ§Ã£o | Tokens Estimados |
|-------|-----------|------------------|
| 1 | PreparaÃ§Ã£o da Infraestrutura | 8.000 |
| 2 | Popular MemÃ³ria com Documentos | 12.000 |
| 3 | Criar NÃ³ de Busca RAG | 10.000 |
| 4 | Testar e Validar | 8.000 |
| 5 | DocumentaÃ§Ã£o | 10.000 |
| 6 | DiÃ¡rio Reflexivo | 5.000 |
| **TOTAL** | **ImplementaÃ§Ã£o Completa** | **53.000 tokens** |

### Margem de SeguranÃ§a

- **Tokens disponÃ­veis:** 123.518 tokens
- **Tokens estimados:** 53.000 tokens
- **Margem de seguranÃ§a:** 70.518 tokens (57% do disponÃ­vel)
- **Viabilidade:** âœ… **MUITO ALTA**

---

## ğŸ¯ BENEFÃCIOS ESPERADOS

### Imediatos

âœ… **AnÃ¡lises mais fundamentadas** - Baseadas em literatura acadÃªmica  
âœ… **ReduÃ§Ã£o de alucinaÃ§Ãµes** - Contexto factual da memÃ³ria  
âœ… **Rastreabilidade** - ReferÃªncias bibliogrÃ¡ficas nas anÃ¡lises  
âœ… **Credibilidade** - Insights apoiados por fontes confiÃ¡veis

### MÃ©dio Prazo

âœ… **EvoluÃ§Ã£o contÃ­nua** - MemÃ³ria cresce com novos documentos  
âœ… **EspecializaÃ§Ã£o** - Agente se torna expert em economia regional  
âœ… **ConsistÃªncia** - AnÃ¡lises alinhadas com conhecimento consolidado  
âœ… **Escalabilidade** - Modelo replicÃ¡vel para outros agentes

---

## ğŸš€ PRÃ“XIMOS PASSOS (PÃ“S-IMPLEMENTAÃ‡ÃƒO)

### OtimizaÃ§Ãµes Futuras

1. **Chunking Inteligente**
   - Usar tÃ©cnicas de semantic chunking
   - Preservar contexto entre chunks

2. **Re-ranking**
   - Adicionar camada de re-ranking dos documentos
   - Melhorar relevÃ¢ncia dos resultados

3. **Feedback Loop**
   - Coletar feedback sobre qualidade das anÃ¡lises
   - Ajustar threshold de similaridade

4. **ExpansÃ£o da MemÃ³ria**
   - Adicionar mais documentos de referÃªncia
   - Incluir anÃ¡lises anteriores bem-sucedidas

### Escalabilidade

1. **Replicar para outros agentes**
   - SOCIAL: Artigos de sociologia e polÃ­ticas sociais
   - AMBIENT: Estudos ambientais e sustentabilidade
   - TERRA: Planejamento urbano e territorial

2. **RAG Corporativo**
   - MemÃ³ria compartilhada entre agentes
   - Conhecimento interdisciplinar

---

## ğŸ’¡ DECISÃ•ES TÃ‰CNICAS

### Por que OpenAI text-embedding-3-small?

- âœ… **Custo-benefÃ­cio:** $0.02 / 1M tokens
- âœ… **Performance:** 1536 dimensÃµes, alta qualidade
- âœ… **Compatibilidade:** IntegraÃ§Ã£o nativa com n8n
- âœ… **Velocidade:** ~100ms por embedding

### Por que pgvector?

- âœ… **IntegraÃ§Ã£o:** JÃ¡ usamos PostgreSQL
- âœ… **Performance:** Ãndices IVFFlat eficientes
- âœ… **Simplicidade:** Sem infraestrutura adicional
- âœ… **Escalabilidade:** Suporta milhÃµes de vetores

### Por que Chunking de 500 tokens?

- âœ… **Contexto:** Suficiente para manter coerÃªncia
- âœ… **RelevÃ¢ncia:** Evita chunks muito genÃ©ricos
- âœ… **Performance:** BalanÃ§o entre precisÃ£o e velocidade

---

## ğŸ“š REFERÃŠNCIAS

### TÃ©cnicas

- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [RAG Best Practices](https://www.pinecone.io/learn/retrieval-augmented-generation/)

### AcadÃªmicas

- Lewis et al. (2020) - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
- Gao et al. (2023) - "Retrieval-Augmented Generation for Large Language Models: A Survey"

---

## âœ… CHECKLIST DE IMPLEMENTAÃ‡ÃƒO

### PrÃ©-requisitos

- [ ] PostgreSQL com extensÃ£o pgvector instalada
- [ ] OpenAI API key configurada
- [ ] Documentos de referÃªncia selecionados
- [ ] Ambiente de teste preparado

### Etapa 1: Infraestrutura

- [ ] ExtensÃ£o pgvector instalada
- [ ] Tabela `agent_econ_memory` criada
- [ ] Ãndices criados
- [ ] FunÃ§Ã£o `search_similar_documents` criada
- [ ] Testes de conexÃ£o realizados

### Etapa 2: Popular MemÃ³ria

- [ ] Documentos baixados
- [ ] Texto extraÃ­do dos PDFs
- [ ] Chunks gerados
- [ ] Embeddings criados
- [ ] Dados salvos no PostgreSQL
- [ ] ValidaÃ§Ã£o de inserÃ§Ã£o

### Etapa 3: Workflow

- [ ] NÃ³ "Buscar Conhecimento RAG" criado
- [ ] NÃ³ "Preparar Contexto para LLM" atualizado
- [ ] Workflow salvo
- [ ] Testes de sintaxe realizados

### Etapa 4: Testes

- [ ] Teste baseline (sem RAG) realizado
- [ ] Teste com RAG realizado
- [ ] ComparaÃ§Ã£o de resultados
- [ ] ValidaÃ§Ã£o de qualidade
- [ ] Ajustes realizados

### Etapa 5: DocumentaÃ§Ã£o

- [ ] IMPLEMENTACAO_RAG_ECON.md criado
- [ ] GUIA_POPULAR_MEMORIA_ECON.md criado
- [ ] TESTE_RAG_ECON.md criado
- [ ] FAQ_RAG_ECON.md criado
- [ ] Commits no GitHub

### Etapa 6: ReflexÃ£o

- [ ] DiÃ¡rio reflexivo criado
- [ ] Aprendizados documentados
- [ ] PrÃ³ximos passos definidos

---

## ğŸ‰ CONCLUSÃƒO

Este plano fornece um roteiro completo e detalhado para implementar RAG no Agente ECON, com:

âœ… **Arquitetura clara** e bem documentada  
âœ… **Estimativas realistas** de tempo e tokens  
âœ… **Scripts prontos** para uso  
âœ… **Testes definidos** para validaÃ§Ã£o  
âœ… **DocumentaÃ§Ã£o completa** para manutenÃ§Ã£o  
âœ… **Margem de seguranÃ§a** confortÃ¡vel (57%)

**Pronto para comeÃ§ar?** ğŸš€

---

**Documento criado por:** Manus AI  
**SessÃ£o:** #6 (26 de novembro de 2025)  
**Framework:** V6.0 - InteligÃªncia Territorial  
**Status:** Plano aprovado, aguardando execuÃ§Ã£o
