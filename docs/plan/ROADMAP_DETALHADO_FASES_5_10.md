# Roadmap Detalhado: Fases 5-10 at√© Publica√ß√£o

## üìã Vis√£o Geral

Este documento detalha todas as funcionalidades que ser√£o implementadas desde a configura√ß√£o inicial do Replit (Fase 5) at√© a valida√ß√£o final do MVP (Fase 10), antes de chegarmos ao ponto de "Publicar Agora".

**Dura√ß√£o Total Estimada:** 15-18 sess√µes (20-27 horas de trabalho)  
**Per√≠odo:** 6-9 semanas (considerando sess√µes curtas de 1-1.5h)

---

## üéØ Fase 5: Configura√ß√£o do Ambiente Replit (1-1.5h)

### Objetivo
Configurar completamente o ambiente de desenvolvimento no Replit com PostgreSQL, extens√µes geoespaciais e vari√°veis de ambiente.

### Funcionalidades Implementadas

#### 5.1 Configura√ß√£o do PostgreSQL
**O que ser√° feito:**
- Ativar PostgreSQL no Replit (via painel Tools ‚Üí PostgreSQL)
- Obter connection string (DATABASE_URL)
- Testar conex√£o com psql
- Verificar vers√£o do PostgreSQL (deve ser 14+)

**Entregas:**
- PostgreSQL rodando no Replit
- Connection string salva
- Teste de conex√£o bem-sucedido

**Crit√©rios de Sucesso:**
- [ ] PostgreSQL ativo e acess√≠vel
- [ ] Connection string funcional
- [ ] Comando `psql $DATABASE_URL` conecta com sucesso

---

#### 5.2 Instala√ß√£o de Extens√µes
**O que ser√° feito:**
- Instalar extens√£o **PostGIS** (dados geoespaciais)
  - Permite armazenar coordenadas, pol√≠gonos, calcular dist√¢ncias
  - Essencial para aba Territorial (mapas)
- Tentar instalar extens√£o **pgvector** (embeddings vetoriais)
  - Para sistema RAG (busca sem√¢ntica)
  - Se n√£o dispon√≠vel, usar busca por texto (fallback)

**Comandos SQL:**
```sql
CREATE EXTENSION IF NOT EXISTS postgis;
CREATE EXTENSION IF NOT EXISTS pgvector; -- pode falhar, ok
```

**Entregas:**
- PostGIS instalado e funcional
- pgvector instalado (ou fallback documentado)

**Crit√©rios de Sucesso:**
- [ ] PostGIS ativo (`SELECT PostGIS_version();` retorna vers√£o)
- [ ] pgvector ativo OU fallback documentado

---

#### 5.3 Configura√ß√£o de Vari√°veis de Ambiente
**O que ser√° feito:**
- Criar arquivo `.env` no Replit
- Adicionar vari√°veis essenciais:
  - `DATABASE_URL` (connection string PostgreSQL)
  - `OPENAI_API_KEY` (sua chave OpenAI)
  - `OPENAI_MODEL` (gpt-4o-mini)
  - `OPENAI_TEMPERATURE` (0.3)
  - `PORT` (3000)
  - `NODE_ENV` (development)

**Entregas:**
- Arquivo `.env` criado
- Todas vari√°veis configuradas
- `.env.example` criado (sem valores sens√≠veis)

**Crit√©rios de Sucesso:**
- [ ] Vari√°veis acess√≠veis no c√≥digo
- [ ] `.env` no `.gitignore`
- [ ] `.env.example` commitado no GitHub

---

#### 5.4 Conectar Replit ao GitHub
**O que ser√° feito:**
- Conectar Repl ao reposit√≥rio `framework-v6-mvp`
- Configurar sincroniza√ß√£o autom√°tica
- Fazer primeiro commit do c√≥digo gerado pelo Agent

**Entregas:**
- Replit conectado ao GitHub
- C√≥digo inicial commitado
- Sincroniza√ß√£o funcionando

**Crit√©rios de Sucesso:**
- [ ] Commits do Replit aparecem no GitHub
- [ ] Pull/push funcionando
- [ ] Hist√≥rico de vers√µes preservado

---

### Checkpoint Fase 5
**Ao final desta fase, voc√™ ter√°:**
- ‚úÖ PostgreSQL configurado e rodando
- ‚úÖ Extens√µes PostGIS (e pgvector se poss√≠vel) instaladas
- ‚úÖ Vari√°veis de ambiente configuradas
- ‚úÖ Replit conectado ao GitHub
- ‚úÖ Ambiente pronto para desenvolvimento

**Tempo:** 1-1.5 horas  
**Sess√µes:** 1 sess√£o

---

## üóÑÔ∏è Fase 6: Implementa√ß√£o do Schema do Banco de Dados (1-2h)

### Objetivo
Criar todas as 40 tabelas do banco de dados com relacionamentos, √≠ndices e constraints.

### Funcionalidades Implementadas

#### 6.1 Tabelas de Dimens√£o (Entidades Territoriais)
**O que ser√° feito:**
- Criar tabela `dim_territorios` (entidade central)
  - Colunas: id, nome, tipo (estado/regi√£o/munic√≠pio), c√≥digo_ibge, geometria (PostGIS), popula√ß√£o, √°rea_km2
  - 140 registros (1 estado + 139 munic√≠pios + regi√µes)
- Criar tabela `dim_divisoes_regionais`
  - Regi√µes intermedi√°rias (3)
  - Regi√µes imediatas (11)
  - Mesorregi√µes hist√≥ricas (2)
  - Microrregi√µes hist√≥ricas (8)
- Criar tabela `dim_tempo`
  - Anos (2005-2025)
  - Trimestres, meses
  - Para s√©ries temporais

**Entregas:**
- 3 tabelas de dimens√£o criadas
- Relacionamentos definidos
- √çndices em chaves prim√°rias e estrangeiras

**Crit√©rios de Sucesso:**
- [ ] Tabelas criadas sem erros
- [ ] Relacionamentos funcionando (foreign keys)
- [ ] Queries de teste retornam dados esperados

---

#### 6.2 Tabelas Fato (Indicadores por Dimens√£o)
**O que ser√° feito:**

**Dimens√£o Econ√¥mica (5 tabelas):**
- `fato_pib` (PIB total, per capita, setorial)
- `fato_emprego` (taxa de emprego, desemprego, formaliza√ß√£o)
- `fato_arrecadacao` (receitas municipais, estaduais)
- `fato_empresas` (n√∫mero de empresas, MEIs, por setor)
- `fato_renda` (renda per capita, sal√°rio m√©dio, Gini)

**Dimens√£o Social (5 tabelas):**
- `fato_demografia` (popula√ß√£o, densidade, crescimento)
- `fato_idh` (IDH-M, componentes: longevidade, educa√ß√£o, renda)
- `fato_educacao` (matr√≠culas, IDEB, taxa alfabetiza√ß√£o)
- `fato_saude` (leitos, m√©dicos per capita, mortalidade)
- `fato_assistencia_social` (Bolsa Fam√≠lia, CRAS, benefici√°rios)

**Dimens√£o Territorial (5 tabelas):**
- `fato_uso_solo` (√°rea urbana, rural, preserva√ß√£o)
- `fato_infraestrutura` (saneamento, energia, internet)
- `fato_mobilidade` (frota ve√≠culos, vias pavimentadas)
- `fato_habitacao` (domic√≠lios, d√©ficit habitacional)
- `fato_equipamentos_publicos` (escolas, postos sa√∫de, delegacias)

**Dimens√£o Ambiental (5 tabelas):**
- `fato_cobertura_vegetal` (√°rea floresta, desmatamento)
- `fato_recursos_hidricos` (qualidade √°gua, disponibilidade)
- `fato_emissoes` (CO‚ÇÇ, poluentes)
- `fato_residuos` (coleta lixo, reciclagem)
- `fato_areas_protegidas` (UCs, APPs, reservas)

**Entregas:**
- 20 tabelas fato criadas
- Chaves estrangeiras para dim_territorios e dim_tempo
- √çndices em colunas de busca frequente

**Crit√©rios de Sucesso:**
- [ ] Todas 20 tabelas criadas
- [ ] Relacionamentos com dimens√µes funcionando
- [ ] Schema validado (sem erros de integridade)

---

#### 6.3 Tabelas de Sistema RAG
**O que ser√° feito:**
- Criar tabela `rag_documentos`
  - Armazena textos de an√°lises, relat√≥rios, leis
  - Colunas: id, titulo, conteudo, fonte, data, territorio_id
- Criar tabela `rag_embeddings` (se pgvector dispon√≠vel)
  - Armazena vetores de embeddings para busca sem√¢ntica
  - Colunas: id, documento_id, embedding (vector(1536)), chunk_text
- Criar tabela `rag_cache`
  - Cache de respostas da IA para economizar custos
  - Colunas: id, query_hash, resposta, territorio_id, dimensao, created_at

**Entregas:**
- 3 tabelas RAG criadas
- √çndices para busca r√°pida
- Triggers para atualiza√ß√£o autom√°tica

**Crit√©rios de Sucesso:**
- [ ] Tabelas RAG criadas
- [ ] √çndices vetoriais (se pgvector) ou full-text search configurados
- [ ] Cache funcionando (teste de insert/select)

---

#### 6.4 Tabelas de Auditoria e Logs
**O que ser√° feito:**
- Criar tabela `log_acessos`
  - Rastreia acessos ao dashboard
  - Colunas: id, usuario_ip, territorio_id, aba, timestamp
- Criar tabela `log_analises_ia`
  - Rastreia an√°lises geradas pela IA
  - Colunas: id, territorio_id, dimensao, prompt, resposta, tokens_usados, custo, timestamp
- Criar tabela `log_exportacoes`
  - Rastreia exporta√ß√µes PDF/CSV
  - Colunas: id, usuario_ip, tipo (pdf/csv), aba, territorio_id, timestamp

**Entregas:**
- 3 tabelas de log criadas
- Triggers para logging autom√°tico
- Queries de an√°lise de uso

**Crit√©rios de Sucesso:**
- [ ] Logs sendo gravados automaticamente
- [ ] Queries de relat√≥rio funcionando
- [ ] Reten√ß√£o de dados configurada (ex: 90 dias)

---

#### 6.5 Views e Fun√ß√µes SQL
**O que ser√° feito:**
- Criar view `vw_dashboard_visao_geral`
  - Agrega KPIs das 4 dimens√µes por territ√≥rio
  - Facilita consultas do dashboard
- Criar view `vw_comparacao_territorios`
  - Dados lado-a-lado para aba Compara√ß√£o
- Criar fun√ß√£o `fn_calcular_ranking`
  - Calcula ranking de territ√≥rios por indicador
- Criar fun√ß√£o `fn_media_regional`
  - Calcula m√©dias por regi√£o intermedi√°ria/imediata

**Entregas:**
- 2 views criadas e testadas
- 2 fun√ß√µes SQL criadas e testadas
- Documenta√ß√£o de uso

**Crit√©rios de Sucesso:**
- [ ] Views retornam dados corretos
- [ ] Fun√ß√µes executam sem erros
- [ ] Performance adequada (queries < 500ms)

---

### Checkpoint Fase 6
**Ao final desta fase, voc√™ ter√°:**
- ‚úÖ 40 tabelas criadas (20 fato + 3 dimens√£o + 3 RAG + 3 log + 11 auxiliares)
- ‚úÖ Relacionamentos e constraints definidos
- ‚úÖ √çndices otimizados
- ‚úÖ Views e fun√ß√µes SQL funcionais
- ‚úÖ Schema completo e validado

**Tempo:** 1-2 horas  
**Sess√µes:** 1-2 sess√µes

---

## üìä Fase 7: Popula√ß√£o Inicial de Dados Territoriais (2-4h)

### Objetivo
Popular o banco de dados com dados reais dos 139 munic√≠pios do Tocantins, estado e divis√µes regionais.

### Funcionalidades Implementadas

#### 7.1 Dados Estruturais (Dimens√µes)
**O que ser√° feito:**
- Popular `dim_territorios` com 140 entidades:
  - 1 registro: Estado do Tocantins
  - 139 registros: Munic√≠pios (nome, c√≥digo IBGE, geometria)
  - Geometrias (pol√≠gonos) obtidas do IBGE
- Popular `dim_divisoes_regionais`:
  - 3 regi√µes intermedi√°rias
  - 11 regi√µes imediatas
  - 2 mesorregi√µes hist√≥ricas
  - 8 microrregi√µes hist√≥ricas
  - Relacionamentos munic√≠pio ‚Üî regi√£o
- Popular `dim_tempo`:
  - Anos 2005-2025
  - Trimestres e meses

**Fonte de Dados:**
- IBGE: Malhas territoriais, c√≥digos, nomes
- Planilha `municipios_tocantins_completo.xlsx` (j√° fornecida)

**Entregas:**
- 140 territ√≥rios cadastrados
- 24 divis√µes regionais cadastradas
- 21 anos de dimens√£o tempo

**Crit√©rios de Sucesso:**
- [ ] 140 registros em dim_territorios
- [ ] Geometrias v√°lidas (PostGIS)
- [ ] Relacionamentos corretos

---

#### 7.2 Dados Econ√¥micos (5 anos iniciais)
**O que ser√° feito:**
- Extrair dados do IBGE (API Sidra)
- Popular tabelas fato_pib, fato_emprego, fato_arrecadacao
- Per√≠odo: 2019-2023 (5 anos)
- 140 territ√≥rios √ó 5 anos = 700 registros por tabela

**APIs Utilizadas:**
- IBGE Sidra: PIB Municipal (tabela 5938)
- IBGE Sidra: Emprego (CAGED)
- Tesouro Nacional: Receitas municipais

**Script Python:**
```python
# scripts/popular_dados_economicos.py
import requests
import psycopg2

def extrair_pib_ibge(ano):
    # Conectar API IBGE Sidra
    # Extrair PIB de todos munic√≠pios TO
    # Retornar DataFrame
    
def popular_banco(df, tabela):
    # Conectar PostgreSQL
    # Inserir dados em lote (bulk insert)
    # Commit
```

**Entregas:**
- Script de extra√ß√£o funcionando
- 3.500+ registros inseridos (700 √ó 5 tabelas)
- Dados validados (sem nulos cr√≠ticos)

**Crit√©rios de Sucesso:**
- [ ] Script executa sem erros
- [ ] Dados consistentes (valores razo√°veis)
- [ ] Queries de teste retornam dados esperados

---

#### 7.3 Dados Sociais (5 anos iniciais)
**O que ser√° feito:**
- Extrair dados do IBGE, INEP, DataSUS
- Popular tabelas fato_demografia, fato_idh, fato_educacao, fato_saude
- Per√≠odo: 2019-2023

**APIs Utilizadas:**
- IBGE: Popula√ß√£o (Estimativas)
- Atlas Brasil: IDH-M (2010, proje√ß√µes)
- INEP: Matr√≠culas, IDEB
- DataSUS: Indicadores de sa√∫de

**Entregas:**
- Script de extra√ß√£o funcionando
- 2.800+ registros inseridos (700 √ó 4 tabelas)

**Crit√©rios de Sucesso:**
- [ ] Dados demogr√°ficos completos
- [ ] IDH-M dispon√≠vel (mesmo que 2010)
- [ ] Indicadores educacionais atualizados

---

#### 7.4 Dados Territoriais (5 anos iniciais)
**O que ser√° feito:**
- Extrair dados do IBGE, SNIS, ANATEL
- Popular tabelas fato_uso_solo, fato_infraestrutura, fato_mobilidade

**APIs Utilizadas:**
- IBGE: √Årea urbanizada
- SNIS: Saneamento b√°sico
- ANATEL: Cobertura internet
- DENATRAN: Frota de ve√≠culos

**Entregas:**
- Script de extra√ß√£o funcionando
- 2.100+ registros inseridos (700 √ó 3 tabelas)

**Crit√©rios de Sucesso:**
- [ ] Dados de infraestrutura completos
- [ ] Geometrias de uso do solo (se dispon√≠veis)

---

#### 7.5 Dados Ambientais (5 anos iniciais)
**O que ser√° feito:**
- Extrair dados do INPE, ANA, IBAMA
- Popular tabelas fato_cobertura_vegetal, fato_recursos_hidricos

**APIs Utilizadas:**
- INPE: Desmatamento (PRODES)
- ANA: Qualidade da √°gua
- MapBiomas: Cobertura vegetal

**Entregas:**
- Script de extra√ß√£o funcionando
- 1.400+ registros inseridos (700 √ó 2 tabelas)

**Crit√©rios de Sucesso:**
- [ ] Dados de desmatamento dispon√≠veis
- [ ] Qualidade da √°gua (IQA) quando dispon√≠vel

---

#### 7.6 Documentos para RAG
**O que ser√° feito:**
- Coletar documentos relevantes:
  - Planos Diretores municipais (PDFs)
  - Leis or√ßament√°rias (LOAs)
  - Relat√≥rios de gest√£o
  - Estudos t√©cnicos
- Processar documentos:
  - Extrair texto (PyPDF2, pdfplumber)
  - Dividir em chunks (1000 tokens)
  - Gerar embeddings (OpenAI text-embedding-3-small)
- Popular tabelas rag_documentos e rag_embeddings

**Entregas:**
- 50-100 documentos processados
- 500-1000 chunks com embeddings
- Sistema de busca sem√¢ntica funcionando

**Crit√©rios de Sucesso:**
- [ ] Documentos indexados
- [ ] Busca sem√¢ntica retorna resultados relevantes
- [ ] Tempo de busca < 1s

---

### Checkpoint Fase 7
**Ao final desta fase, voc√™ ter√°:**
- ‚úÖ 140 territ√≥rios cadastrados
- ‚úÖ 10.000+ registros de indicadores (5 anos √ó 4 dimens√µes)
- ‚úÖ 50-100 documentos indexados para RAG
- ‚úÖ Banco de dados populado e funcional
- ‚úÖ Scripts de extra√ß√£o documentados e versionados

**Tempo:** 2-4 horas  
**Sess√µes:** 2-3 sess√µes

---

## üîó Fase 8: Configura√ß√£o do n8n Cloud e Implementa√ß√£o do Data Collector (4-6h)

### Objetivo
Configurar n8n Cloud, criar conta, implementar o agente Data Collector para automa√ß√£o de coleta de dados.

### Funcionalidades Implementadas

#### 8.1 Configura√ß√£o do n8n Cloud
**O que ser√° feito:**
- Criar conta no n8n Cloud (https://n8n.io)
- Escolher plano (Starter: $20/m√™s)
- Configurar workspace
- Conectar credenciais:
  - PostgreSQL (Replit DATABASE_URL)
  - OpenAI API Key
  - IBGE API (sem autentica√ß√£o)
  - Outras APIs governamentais

**Entregas:**
- Conta n8n ativa
- Workspace configurado
- Credenciais salvas

**Crit√©rios de Sucesso:**
- [ ] n8n acess√≠vel
- [ ] Credenciais testadas e funcionando
- [ ] Primeiro workflow de teste executado

---

#### 8.2 Workflow: Data Collector - Econ√¥mico
**O que ser√° feito:**
- Criar workflow no n8n para coletar dados econ√¥micos
- Componentes:
  1. **Trigger:** Schedule (di√°rio, semanal ou mensal)
  2. **HTTP Request:** Chamar API IBGE Sidra (PIB)
  3. **Code:** Processar JSON, transformar dados
  4. **PostgreSQL:** Inserir em fato_pib
  5. **IF:** Verificar se dados novos ou atualiza√ß√£o
  6. **Notification:** Enviar email/Slack se erro

**Fluxo:**
```
[Schedule Trigger]
    ‚Üì
[HTTP Request: IBGE PIB]
    ‚Üì
[Code: Transform Data]
    ‚Üì
[PostgreSQL: Upsert fato_pib]
    ‚Üì
[IF: Success?]
    ‚îú‚îÄ Yes ‚Üí [Log Success]
    ‚îî‚îÄ No ‚Üí [Send Alert]
```

**Entregas:**
- Workflow funcionando
- Dados sendo coletados automaticamente
- Logs de execu√ß√£o

**Crit√©rios de Sucesso:**
- [ ] Workflow executa sem erros
- [ ] Dados inseridos corretamente no banco
- [ ] Alertas funcionando em caso de erro

---

#### 8.3 Workflow: Data Collector - Social
**O que ser√° feito:**
- Workflow para coletar dados sociais (IBGE, INEP, DataSUS)
- Similar ao econ√¥mico, mas com m√∫ltiplas APIs
- Merge de dados de diferentes fontes

**Entregas:**
- Workflow funcionando
- Dados de 3+ fontes integrados

**Crit√©rios de Sucesso:**
- [ ] Dados demogr√°ficos atualizados
- [ ] Indicadores educacionais coletados
- [ ] Merge sem duplicatas

---

#### 8.4 Workflow: Data Collector - Territorial
**O que ser√° feito:**
- Workflow para coletar dados territoriais (IBGE, SNIS, ANATEL)
- Incluir processamento de dados geoespaciais (se necess√°rio)

**Entregas:**
- Workflow funcionando
- Dados de infraestrutura atualizados

**Crit√©rios de Sucesso:**
- [ ] Dados de saneamento coletados
- [ ] Cobertura de internet atualizada

---

#### 8.5 Workflow: Data Collector - Ambiental
**O que ser√° feito:**
- Workflow para coletar dados ambientais (INPE, ANA, MapBiomas)
- Processar dados de desmatamento e qualidade da √°gua

**Entregas:**
- Workflow funcionando
- Dados ambientais atualizados

**Crit√©rios de Sucesso:**
- [ ] Dados de desmatamento (PRODES) coletados
- [ ] Qualidade da √°gua (quando dispon√≠vel)

---

#### 8.6 Workflow: Orquestrador (Meta-Workflow)
**O que ser√° feito:**
- Criar workflow "mestre" que coordena os 4 Data Collectors
- Executa em sequ√™ncia ou paralelo
- Gera relat√≥rio de execu√ß√£o
- Envia notifica√ß√£o de conclus√£o

**Fluxo:**
```
[Schedule: Weekly]
    ‚Üì
[Execute: Data Collector Econ√¥mico]
    ‚Üì
[Execute: Data Collector Social]
    ‚Üì
[Execute: Data Collector Territorial]
    ‚Üì
[Execute: Data Collector Ambiental]
    ‚Üì
[Generate Report]
    ‚Üì
[Send Email: Summary]
```

**Entregas:**
- Orquestrador funcionando
- Relat√≥rios autom√°ticos
- Notifica√ß√µes configuradas

**Crit√©rios de Sucesso:**
- [ ] Todos workflows executam corretamente
- [ ] Relat√≥rio gerado com estat√≠sticas
- [ ] Email recebido ap√≥s execu√ß√£o

---

### Checkpoint Fase 8
**Ao final desta fase, voc√™ ter√°:**
- ‚úÖ n8n Cloud configurado
- ‚úÖ 4 workflows Data Collector funcionando (1 por dimens√£o)
- ‚úÖ 1 workflow orquestrador
- ‚úÖ Coleta autom√°tica de dados (semanal/mensal)
- ‚úÖ Alertas e notifica√ß√µes configurados
- ‚úÖ Banco de dados sempre atualizado

**Tempo:** 4-6 horas  
**Sess√µes:** 3-4 sess√µes

---

## ü§ñ Fase 9: Implementa√ß√£o do Sistema RAG (4-6h)

### Objetivo
Implementar sistema RAG (Retrieval-Augmented Generation) para gera√ß√£o de an√°lises contextualizadas pela IA.

### Funcionalidades Implementadas

#### 9.1 Backend Python: Servi√ßo RAG
**O que ser√° feito:**
- Criar m√≥dulo `services/rag_service.py`
- Implementar fun√ß√µes:
  - `gerar_embedding(texto)`: Gera embedding de texto
  - `buscar_documentos_relevantes(query, territorio_id, top_k=5)`: Busca sem√¢ntica
  - `gerar_analise(territorio_id, dimensao, contexto)`: Gera an√°lise com RAG

**C√≥digo Exemplo:**
```python
from openai import OpenAI
import psycopg2

client = OpenAI()

def gerar_embedding(texto):
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=texto
    )
    return response.data[0].embedding

def buscar_documentos_relevantes(query, territorio_id, top_k=5):
    query_embedding = gerar_embedding(query)
    
    # Busca vetorial (se pgvector dispon√≠vel)
    sql = """
    SELECT chunk_text, 1 - (embedding <=> %s::vector) AS similarity
    FROM rag_embeddings
    WHERE territorio_id = %s
    ORDER BY similarity DESC
    LIMIT %s
    """
    # Executar query, retornar resultados
    
def gerar_analise(territorio_id, dimensao, contexto):
    # 1. Buscar documentos relevantes
    docs = buscar_documentos_relevantes(
        f"An√°lise {dimensao} de {territorio_id}", 
        territorio_id
    )
    
    # 2. Buscar dados quantitativos do banco
    dados = obter_dados_dimensao(territorio_id, dimensao)
    
    # 3. Construir prompt contextual
    prompt = f"""
    Voc√™ √© um analista de intelig√™ncia territorial.
    
    Territ√≥rio: {territorio_id}
    Dimens√£o: {dimensao}
    
    Dados Quantitativos:
    {dados}
    
    Documentos Relevantes:
    {docs}
    
    Gere uma an√°lise de 150-250 palavras sobre a dimens√£o {dimensao} 
    do territ√≥rio, incluindo:
    - Contexto atual
    - Principais insights
    - Alertas ou oportunidades
    
    Use linguagem acess√≠vel para gestores p√∫blicos.
    """
    
    # 4. Chamar OpenAI
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=500
    )
    
    return response.choices[0].message.content
```

**Entregas:**
- M√≥dulo `rag_service.py` funcionando
- Fun√ß√µes testadas e validadas
- Documenta√ß√£o de uso

**Crit√©rios de Sucesso:**
- [ ] Embeddings gerados corretamente
- [ ] Busca sem√¢ntica retorna documentos relevantes
- [ ] An√°lises geradas s√£o coerentes e √∫teis

---

#### 9.2 API REST: Endpoint de An√°lise
**O que ser√° feito:**
- Criar endpoint FastAPI: `POST /api/analise`
- Recebe: `territorio_id`, `dimensao`
- Retorna: An√°lise gerada pela IA

**C√≥digo Exemplo:**
```python
from fastapi import FastAPI, HTTPException
from services.rag_service import gerar_analise

app = FastAPI()

@app.post("/api/analise")
async def criar_analise(territorio_id: int, dimensao: str):
    try:
        analise = gerar_analise(territorio_id, dimensao, contexto={})
        
        # Salvar em log_analises_ia
        salvar_log(territorio_id, dimensao, analise)
        
        return {"analise": analise, "territorio_id": territorio_id, "dimensao": dimensao}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

**Entregas:**
- Endpoint funcionando
- Testes de API (Postman/curl)
- Documenta√ß√£o OpenAPI/Swagger

**Crit√©rios de Sucesso:**
- [ ] Endpoint responde em < 5s
- [ ] An√°lises geradas s√£o relevantes
- [ ] Erros tratados adequadamente

---

#### 9.3 Integra√ß√£o Frontend: Caixa de An√°lise IA
**O que ser√° feito:**
- Conectar componente `AIAnalysisBox` ao endpoint `/api/analise`
- Implementar loading state (skeleton screen)
- Exibir an√°lise gerada
- Adicionar bot√£o "Regenerar"

**C√≥digo React:**
```typescript
const AIAnalysisBox = ({ territorioId, dimensao }) => {
  const [analise, setAnalise] = useState('');
  const [loading, setLoading] = useState(true);
  
  useEffect(() => {
    const fetchAnalise = async () => {
      setLoading(true);
      const response = await fetch('/api/analise', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ territorio_id: territorioId, dimensao })
      });
      const data = await response.json();
      setAnalise(data.analise);
      setLoading(false);
    };
    
    fetchAnalise();
  }, [territorioId, dimensao]);
  
  if (loading) return <SkeletonLoader />;
  
  return (
    <div className="ai-analysis-box">
      <h3>An√°lise {dimensao} por IA</h3>
      <p>{analise}</p>
      <button onClick={() => fetchAnalise()}>Regenerar</button>
    </div>
  );
};
```

**Entregas:**
- Componente integrado
- Loading states funcionando
- Regenera√ß√£o de an√°lise

**Crit√©rios de Sucesso:**
- [ ] An√°lise carrega automaticamente ao trocar aba/territ√≥rio
- [ ] Loading state exibido durante gera√ß√£o
- [ ] Bot√£o "Regenerar" funciona

---

#### 9.4 Chat IA: Integra√ß√£o Contextual
**O que ser√° feito:**
- Conectar componente `ChatSidebar` ao endpoint de chat
- Criar endpoint `POST /api/chat`
- Implementar contexto autom√°tico (aba, territ√≥rio, indicadores vis√≠veis)
- Sugest√µes de perguntas contextuais

**Endpoint de Chat:**
```python
@app.post("/api/chat")
async def chat(mensagem: str, territorio_id: int, dimensao: str, contexto: dict):
    # 1. Buscar documentos relevantes
    docs = buscar_documentos_relevantes(mensagem, territorio_id)
    
    # 2. Buscar dados quantitativos
    dados = obter_dados_dimensao(territorio_id, dimensao)
    
    # 3. Construir prompt com contexto
    prompt = f"""
    Voc√™ √© um assistente de intelig√™ncia territorial.
    
    Contexto:
    - Territ√≥rio: {territorio_id}
    - Dimens√£o ativa: {dimensao}
    - Indicadores vis√≠veis: {contexto.get('indicadores')}
    
    Dados:
    {dados}
    
    Documentos:
    {docs}
    
    Pergunta do usu√°rio:
    {mensagem}
    
    Responda de forma objetiva (150-250 palavras), com dados quantitativos.
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return {"resposta": response.choices[0].message.content}
```

**Entregas:**
- Chat funcional
- Contexto autom√°tico funcionando
- Sugest√µes de perguntas

**Crit√©rios de Sucesso:**
- [ ] Chat responde perguntas corretamente
- [ ] Respostas s√£o contextualizadas
- [ ] Sugest√µes mudam conforme aba/territ√≥rio

---

#### 9.5 Cache de An√°lises (Otimiza√ß√£o de Custos)
**O que ser√° feito:**
- Implementar cache em `rag_cache`
- Antes de chamar OpenAI, verificar se an√°lise j√° existe
- Hash da query: `md5(territorio_id + dimensao + data)`
- TTL: 7 dias (an√°lises expiram ap√≥s 1 semana)

**L√≥gica:**
```python
def gerar_analise_com_cache(territorio_id, dimensao):
    # 1. Calcular hash
    query_hash = hashlib.md5(f"{territorio_id}{dimensao}{date.today()}".encode()).hexdigest()
    
    # 2. Buscar no cache
    cached = buscar_cache(query_hash)
    if cached and (datetime.now() - cached.created_at).days < 7:
        return cached.resposta
    
    # 3. Gerar nova an√°lise
    analise = gerar_analise(territorio_id, dimensao, contexto={})
    
    # 4. Salvar no cache
    salvar_cache(query_hash, analise, territorio_id, dimensao)
    
    return analise
```

**Entregas:**
- Cache implementado
- Redu√ß√£o de 70% nas chamadas OpenAI
- Economia de custos

**Crit√©rios de Sucesso:**
- [ ] Cache funcionando
- [ ] An√°lises repetidas n√£o chamam OpenAI
- [ ] Custo mensal reduzido para $5-7

---

### Checkpoint Fase 9
**Ao final desta fase, voc√™ ter√°:**
- ‚úÖ Sistema RAG completo e funcional
- ‚úÖ An√°lises IA geradas automaticamente em cada aba
- ‚úÖ Chat IA contextual funcionando
- ‚úÖ Cache implementado (70% economia)
- ‚úÖ APIs REST documentadas
- ‚úÖ Integra√ß√£o frontend-backend completa

**Tempo:** 4-6 horas  
**Sess√µes:** 3-4 sess√µes

---

## ‚úÖ Fase 10: Testes Integrados e Valida√ß√£o do MVP (2-3h)

### Objetivo
Realizar testes completos do sistema, validar funcionalidades, corrigir bugs e preparar para publica√ß√£o.

### Funcionalidades Implementadas

#### 10.1 Testes Funcionais (Todas as Abas)
**O que ser√° feito:**
- Testar cada aba individualmente:
  - **Vis√£o Geral:** KPIs carregam, an√°lise IA gerada, badges corretos
  - **Econ√¥mica:** Gr√°ficos renderizam, dados corretos, tabela export√°vel
  - **Social:** Gr√°fico radar funciona, dados demogr√°ficos corretos
  - **Territorial:** Mapa interativo carrega, uso do solo correto
  - **Ambiental:** Gr√°ficos ambientais, dados INPE/ANA corretos
  - **Compara√ß√£o:** Seletor multi-territ√≥rio funciona, gr√°ficos comparativos corretos

**Checklist:**
- [ ] Todas as 6 abas naveg√°veis
- [ ] KPIs exibem valores corretos
- [ ] Gr√°ficos renderizam sem erros
- [ ] An√°lises IA s√£o geradas
- [ ] Tabelas exibem dados corretos
- [ ] Exporta√ß√£o PDF/CSV funciona

---

#### 10.2 Testes de Seletores e Filtros
**O que ser√° feito:**
- Testar painel de controle:
  - Seletor de tipo de territ√≥rio (6 op√ß√µes)
  - Seletor de territ√≥rio espec√≠fico (140 op√ß√µes, busca)
  - Seletor de per√≠odo (5/10/20 anos)
  - Seletor de indicadores (multi-select)
- Verificar atualiza√ß√£o de dados ao mudar seletores

**Checklist:**
- [ ] Seletores funcionam corretamente
- [ ] Busca de territ√≥rio funciona
- [ ] Dados atualizam ao mudar sele√ß√£o
- [ ] Filtros persistem ao trocar abas

---

#### 10.3 Testes do Chat IA
**O que ser√° feito:**
- Testar chat em diferentes contextos:
  - Perguntas sobre dimens√£o econ√¥mica
  - Perguntas sobre compara√ß√£o entre munic√≠pios
  - Perguntas sobre dados hist√≥ricos
- Verificar sugest√µes contextuais
- Testar exporta√ß√£o de conversa

**Checklist:**
- [ ] Chat responde perguntas corretamente
- [ ] Respostas s√£o contextualizadas
- [ ] Sugest√µes mudam conforme contexto
- [ ] Exporta√ß√£o de conversa funciona
- [ ] Typing indicator aparece

---

#### 10.4 Testes de Responsividade
**O que ser√° feito:**
- Testar em 3 tamanhos:
  - Desktop (1920x1080, 1280x720)
  - Tablet (768x1024)
  - Mobile (375x667, 414x896)
- Verificar adapta√ß√µes:
  - Chat em drawer (tablet)
  - Chat fullscreen (mobile)
  - Abas em accordion (mobile)
  - KPIs em grid 2x2 (mobile)

**Checklist:**
- [ ] Layout responsivo em todos tamanhos
- [ ] Chat se adapta corretamente
- [ ] Bot√µes touch-friendly (min 44x44px)
- [ ] Gr√°ficos redimensionam
- [ ] Tabelas com scroll horizontal

---

#### 10.5 Testes de Performance
**O que ser√° feito:**
- Medir tempos de carregamento:
  - Carregamento inicial: < 3s
  - Troca de aba: < 500ms
  - Gera√ß√£o de an√°lise IA: < 5s
  - Busca de territ√≥rio: < 200ms
- Otimizar queries lentas
- Implementar lazy loading

**Checklist:**
- [ ] Carregamento inicial < 3s
- [ ] Navega√ß√£o fluida (< 500ms)
- [ ] An√°lises IA < 5s
- [ ] Queries otimizadas

---

#### 10.6 Testes de Exporta√ß√£o
**O que ser√° feito:**
- Testar exporta√ß√£o PDF:
  - Aba individual
  - Dashboard completo
  - Com/sem hist√≥rico de chat
- Testar exporta√ß√£o CSV:
  - Dados da tabela atual
  - Metadados inclu√≠dos
- Verificar formata√ß√£o

**Checklist:**
- [ ] PDF gerado corretamente
- [ ] CSV exporta dados corretos
- [ ] Formata√ß√£o adequada
- [ ] Metadados inclu√≠dos

---

#### 10.7 Testes de Integra√ß√£o n8n
**O que ser√° feito:**
- Verificar workflows n8n:
  - Data Collectors executam sem erros
  - Dados inseridos no banco corretamente
  - Alertas funcionando
- Testar execu√ß√£o manual e agendada

**Checklist:**
- [ ] Workflows executam sem erros
- [ ] Dados atualizados no banco
- [ ] Alertas recebidos
- [ ] Logs de execu√ß√£o dispon√≠veis

---

#### 10.8 Corre√ß√£o de Bugs
**O que ser√° feito:**
- Listar todos bugs encontrados
- Priorizar por severidade (cr√≠tico, alto, m√©dio, baixo)
- Corrigir bugs cr√≠ticos e altos
- Documentar bugs m√©dios/baixos para vers√µes futuras

**Entregas:**
- Lista de bugs documentada
- Bugs cr√≠ticos corrigidos
- Plano para bugs restantes

**Crit√©rios de Sucesso:**
- [ ] Zero bugs cr√≠ticos
- [ ] < 3 bugs altos n√£o corrigidos
- [ ] Bugs documentados no GitHub Issues

---

#### 10.9 Valida√ß√£o com Usu√°rio (Opcional)
**O que ser√° feito:**
- Convidar 1-2 gestores p√∫blicos para testar
- Observar uso real do dashboard
- Coletar feedback
- Ajustar UX conforme necess√°rio

**Entregas:**
- Sess√£o de teste com usu√°rios
- Feedback documentado
- Ajustes implementados

**Crit√©rios de Sucesso:**
- [ ] Usu√°rios conseguem navegar sem ajuda
- [ ] Feedback positivo sobre usabilidade
- [ ] Principais dores de UX resolvidas

---

#### 10.10 Documenta√ß√£o Final
**O que ser√° feito:**
- Atualizar README.md com instru√ß√µes de uso
- Criar MANUAL_USUARIO.md (para gestores p√∫blicos)
- Documentar APIs (Swagger/OpenAPI)
- Criar v√≠deo tutorial (5-10 min)

**Entregas:**
- README.md atualizado
- Manual do usu√°rio completo
- Documenta√ß√£o de APIs
- V√≠deo tutorial (opcional)

**Crit√©rios de Sucesso:**
- [ ] Documenta√ß√£o clara e completa
- [ ] Manual acess√≠vel para n√£o-t√©cnicos
- [ ] APIs documentadas (Swagger)

---

### Checkpoint Fase 10
**Ao final desta fase, voc√™ ter√°:**
- ‚úÖ MVP completamente testado
- ‚úÖ Bugs cr√≠ticos corrigidos
- ‚úÖ Performance otimizada
- ‚úÖ Responsividade validada
- ‚úÖ Documenta√ß√£o completa
- ‚úÖ Sistema pronto para publica√ß√£o

**Tempo:** 2-3 horas  
**Sess√µes:** 2 sess√µes

---

## üöÄ Ap√≥s Fase 10: Publica√ß√£o

### Quando Publicar?
**Somente quando TODOS os crit√©rios forem atendidos:**

‚úÖ Todas as 6 abas funcionando perfeitamente  
‚úÖ Chat IA respondendo corretamente  
‚úÖ Banco de dados populado (140 entidades, 10.000+ registros)  
‚úÖ n8n workflows funcionando (coleta autom√°tica)  
‚úÖ Sistema RAG gerando an√°lises relevantes  
‚úÖ Exporta√ß√£o PDF/CSV funcionando  
‚úÖ Responsividade validada (desktop, tablet, mobile)  
‚úÖ Performance adequada (< 3s carregamento)  
‚úÖ Zero bugs cr√≠ticos  
‚úÖ Documenta√ß√£o completa  
‚úÖ Testes com usu√°rios realizados (opcional)  

### Como Publicar?
1. Voltar √†s configura√ß√µes de "Production database settings"
2. Verificar configura√ß√µes (Op√ß√£o 1 marcada)
3. Clicar em **"Publish now"**
4. Replit cria banco de produ√ß√£o
5. Deploy autom√°tico
6. URL p√∫blica gerada
7. Compartilhar com gestores p√∫blicos

---

## üìä Resumo Geral

| Fase | Objetivo | Tempo | Sess√µes | Status |
|------|----------|-------|---------|--------|
| 5 | Configura√ß√£o Replit | 1-1.5h | 1 | ‚è≥ Pr√≥xima |
| 6 | Schema do Banco | 1-2h | 1-2 | üîú Aguardando |
| 7 | Popula√ß√£o de Dados | 2-4h | 2-3 | üîú Aguardando |
| 8 | n8n + Data Collector | 4-6h | 3-4 | üîú Aguardando |
| 9 | Sistema RAG | 4-6h | 3-4 | üîú Aguardando |
| 10 | Testes e Valida√ß√£o | 2-3h | 2 | üîú Aguardando |
| **Total** | **MVP Completo** | **15-22h** | **12-16** | **30% Conclu√≠do** |

---

## üéØ Pr√≥ximo Passo Imediato

**Voc√™ est√° agora na Fase 5!**

Ap√≥s o Replit Agent terminar de gerar o c√≥digo (Fase 3-4), voc√™ vai:
1. Configurar PostgreSQL no Replit
2. Instalar extens√µes (PostGIS, pgvector)
3. Configurar vari√°veis de ambiente
4. Conectar ao GitHub
5. Fazer primeiro commit

**Tempo estimado:** 1-1.5 horas  
**Quando:** Ap√≥s Replit Agent concluir gera√ß√£o do c√≥digo

---

Tem alguma d√∫vida sobre alguma fase espec√≠fica? Posso detalhar mais qualquer etapa! üöÄ
